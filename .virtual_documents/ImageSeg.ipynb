import numpy as np
#we import numpy here for it's mathematical functions on arrays and multidimensional arrays
#we mostly use it here to arrange the labels on the confusion matrix.
#numpy is also used for the manipulation of array and it has functions that can contribute with mathematical equations such as linear algebra.

import cv2
#cv2 is a python library used for image processing. It can perform functions like filtering, object recognition, etc..
#cv2 allows users to develop, read, write, and manipulate the images with ease. 
#This import supports real-time image processing for application with advanced visions. It also 
#supports machine learning models that is widely used in robotics.

import matplotlib.pyplot as plt
#matplotlib is mostly used for the creation and visualization of graphs.
#matplotlib is the standard for most graphing and plotting in python
#it works by creating figures and plots and graphs inside the figures which we can add data to.

import pandas as pd 
#Pandas is a python library that is mostly used for its ability to examine, clean, analyze, and modify data within the dataframe.
#this is an import for adding the dataframes we will manipulate and it also displays data in tabular form


img = cv2.imread("6p.jpg", cv2.IMREAD_COLOR)
#This line of code reads the image in color mode that has a default format of BGR(Blue, Green, Red)
#IMREAD_COLOR specifies that the image should be read in color mode. The Integer 1 can also
#be used instead of cv2.IMREAD_COLOR, both of them are the same.

img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#The cvtColor() function converts an image from one color space to another and there are 150 color-space conversions available.
#In this case we converted the BGR to an RGB color space.
#Color would seem inverted/incorrect when visualizing with non-OpenCV if the conversion is not applied.


plt.title('Raw Image')
#This line of code adds a title on the uppermost part of the image
#We used this to label the image to avoid confusion in preprocessing.

plt.imshow(img)
#This line of code load and shows the image to the screen.
#We used this to confirm if the image exists and is loadable.


img_bnw = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
# There are 150 color-space conversions available, and the cvtColor() function can change an image's color space.
# In this instance, the BGR was changed to a grayscale color space.

plt.title('Black and White Image')
#This line of code adds a title on the uppermost part of the image
#We used this to label the image to avoid confusion in preprocessing.

plt.imshow(img_bnw, cmap="gray")
#We used this in order to confirm if the image is really converted into a gray color space.
#This line of code also loads and shows the image to the screen.


img_blur = cv2.GaussianBlur(img_bnw, (15, 15), 0)
#cv2.GaussianBlur is a method that is used to make an image smoother by reducing its noise and detail
#The parameters define how much blur does it have in the x and y direction. the '0' states that
#OpenCV would automaticlly caclulate the standart deviation based on its kernel size.

plt.title('Blurred Image')
#This line of code adds a title on the uppermost part of the image
#We used this to label the image to avoid confusion in preprocessing.

plt.imshow(img_blur, cmap = "gray")
#We used this to confirm if the Gaussian Blur is applied to the image. As we can see
#the image is blurred our resulting into a smoother texture.
#This line of code also loads and shows the image to the screen.


ret, thresh_otsu = cv2.threshold(img_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
#Otsu's Tresholding separates the image into two classes which is Foreground and Background.
#It finds a point between dark and bright pixels and where is it clearest. 
#This line of code finds the best treshold value automatically by analyzing the histogram. 
#It minimizes the variance of each classes which results in an optimal image segmentation.

plt.title('Otsu\'s Tresholding')
#This line of code adds a title on the uppermost part of the image
#We used this to label the image to avoid confusion in preprocessing.

plt.imshow(thresh_otsu, cmap = "gray")
#We used this in order to confirm if the Otsu Tresholding is applied. As we can see in the image below, 
#it looks black and white which is the binary version of a grayscale image.
#We can also see that it separates the image into two parts being foreground and background.
#This line of code also loads and shows the image to the screen.


thresh_adaptive = cv2.adaptiveThreshold(img_blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,9,2)
#This line of code a pplies the adaptive tresholding function using te Gaussian model to convert 
#a blurred image that is also in grayscale into a binary image.
#The reason we ned this is to fix Uneven Lighting, and improvements for feature detection, etc...

plt.title('Adaptive Treshold')
#This line of code adds a title on the uppermost part of the image
#We used this to label the image to avoid confusion in preprocessing.

plt.imshow(thresh_adaptive, cmap = "gray")
#We used this to confirm if the Adaptive Treshold function is applied. As we can see in the image below,
#Sharp edges and features are highlighted even in areas where there is uneven lighting..
#This line of code also loads and shows the image to the screen.


edges = cv2.Canny(img_blur,5, 30)
#This line of codee detects the edges of an image. It does it by the sharp changes in intensity such as outlines.
#This fins the edges in te blurred image which would identify and isolate the shapes for further processing.

plt.title('Edge Detection (Canny)')
plt.imshow(edges, cmap = "gray")


img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)

H_lower = 20
H_higher = 30
S_lower = 48
S_higher = 255
V_lower = 50
V_higher = 255

lower = np.array([H_lower, S_lower, V_lower])
higher = np.array([H_higher, S_higher, V_higher])

mask = cv2.inRange(img_hsv, lower, higher)

img_highlight = cv2.bitwise_and(img, img, mask = mask)

fig, ax = plt.subplots(1, 2)

ax[0].set_title('Mask')
ax[1].set_title('Mask Overlayed Over Original Image')
plt.tight_layout()

ax[0].imshow(mask, cmap='gray', vmin=0, vmax=255)
ax[1].imshow(img_highlight)
plt.show()


kernel = np.ones((5,5), np.uint8)
dilation = cv2.dilate(img_blur,kernel,iterations = 1)
erosion = cv2.erode(img_blur,kernel,iterations = 1)


fig, ax = plt.subplots(1, 3)

ax[0].set_title('Gaussian Blurr')
ax[1].set_title('Dilation')
ax[2].set_title('Errosion')
    
ax[0].imshow(img_blur, cmap='gray')
ax[1].imshow(dilation, cmap = "gray")
ax[2].imshow(erosion, cmap = "gray")
plt.show()


params = cv2.SimpleBlobDetector_Params()

image_to_blob = dilation

params.filterByArea = True
params.minArea = 100
params.filterByColor = True
params.blobColor = 255
params.filterByCircularity = False
params.filterByConvexity = False
params.filterByInertia = False

detector = cv2.SimpleBlobDetector_create(params)

keypoints = detector.detect(image_to_blob)
img_with_keypoints = cv2.drawKeypoints(image_to_blob, keypoints, np.array([]), (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

plt.title('Blob Detection')

plt.imshow(img_with_keypoints, cmap = "gray")
count = 0

keypoint_data = []

for keypoint in keypoints:
    data = {}
    data["Coorrdinates"] = keypoint.pt
    data["Size"] = keypoint.size
    keypoint_data.append(data)
    count += 1
keypoint_data = pd.DataFrame(keypoint_data)
keypoint_data


img_box = img.copy()

new_img = img_blur.copy()
ret, new_otsu = cv2.threshold(new_img, 100, 255, cv2.THRESH_OTSU)

contours, hierarchy = cv2.findContours(new_otsu, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

AREA_THRESH = 1500

features = []

for contour in contours:
    area = cv2.contourArea(contour)
    if area > AREA_THRESH:
        moment = cv2.moments(contour)
        center_x = int(moment['m10']/moment['m00'])
        center_y = int(moment['m01']/moment['m00'])

        cv2.circle(img_box, (center_x, center_y), 7, (0, 0, 255), -1)
        
        rect_x, rect_y, rect_w, rect_h = cv2.boundingRect(contour)
        min_rect = cv2.minAreaRect(contour)
        img_box = cv2.rectangle(img_box,
                                (rect_x, rect_y),
                                (rect_x + rect_w, rect_y + rect_h),
                                (0, 255, 0),
                                2)
        min_box = cv2.boxPoints(min_rect)
        min_box = min_box.astype(np.intp)
        cv2.drawContours(img_box, [min_box], 0, (0,0,255), 2)
        
        #perimeter, aspect ratio, extent, solidity, equivalent diameter, orientation
        feature = {}
        feature["Perimeter"] = cv2.arcLength(contour, True)
        feature["Aspect Ratio"] = rect_w/rect_h
        feature["Extent"] = float(area) / (rect_w * rect_h)
        hull = cv2.convexHull(contour)
        hull_area = cv2.contourArea(hull)
        feature["Solidity"] = float(area) / hull_area if hull_area > 0 else 0
        feature["Diameter"] = np.sqrt(4 * area / np.pi).item()
        
        angle = None
        if len(contour) >= 5:
            ellipse = cv2.fitEllipse(contour)
            angle = ellipse[2]
        feature["Orientation"] = angle

        features.append(feature)
features = pd.DataFrame(features)

plt.title('Shape Detection Using Contours')
plt.imshow(img_box)
features



